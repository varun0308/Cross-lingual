{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pre - Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Lingual Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry sir nim yella video nan nodidini yeno ma...</td>\n",
       "      <td>Mixed_feelings</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bro nin ello hogbutte bedu bro</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡≤™‡≥É‡≤•‡≥ç‡≤µ‡≤ø ‡≤Ö‡≤Ç‡≤¨‡≤∞‡≥ç ‡≤è‡≤®‡≥ç  ‡≤ó‡≥Å‡≤∞‡≥Ç ‡≤®‡≥Ä‡≤®‡≥Å national award win...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡≤∏‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤§‡≥ç‡≤•‡≤æ‡≤Æ ‡≤Ü ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞ ‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤¨‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶ ‡≤Ö‡≤Ç‡≤§ ‡≤π‡≥á...</td>\n",
       "      <td>unknown_state</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best song ever</td>\n",
       "      <td>not-Kannada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Cross Lingual Text       Sentiment  \\\n",
       "0  Sorry sir nim yella video nan nodidini yeno ma...  Mixed_feelings   \n",
       "1                     Bro nin ello hogbutte bedu bro        Positive   \n",
       "2  ‡≤™‡≥É‡≤•‡≥ç‡≤µ‡≤ø ‡≤Ö‡≤Ç‡≤¨‡≤∞‡≥ç ‡≤è‡≤®‡≥ç  ‡≤ó‡≥Å‡≤∞‡≥Ç ‡≤®‡≥Ä‡≤®‡≥Å national award win...        Positive   \n",
       "3  ‡≤∏‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤§‡≥ç‡≤•‡≤æ‡≤Æ ‡≤Ü ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞ ‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤¨‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶ ‡≤Ö‡≤Ç‡≤§ ‡≤π‡≥á...   unknown_state   \n",
       "4                                     best song ever     not-Kannada   \n",
       "\n",
       "   Unnamed: 2  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kapil\\OneDrive\\Desktop\\ML\\NLP\\kannada_sentiment_train.csv\",delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Sentiment\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 2\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cross Lingual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorry sir nim yella video nan nodidini yeno ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bro nin ello hogbutte bedu bro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡≤™‡≥É‡≤•‡≥ç‡≤µ‡≤ø ‡≤Ö‡≤Ç‡≤¨‡≤∞‡≥ç ‡≤è‡≤®‡≥ç  ‡≤ó‡≥Å‡≤∞‡≥Ç ‡≤®‡≥Ä‡≤®‡≥Å national award win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡≤∏‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤§‡≥ç‡≤•‡≤æ‡≤Æ ‡≤Ü ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞ ‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤¨‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶ ‡≤Ö‡≤Ç‡≤§ ‡≤π‡≥á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best song ever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Cross Lingual Text\n",
       "0  Sorry sir nim yella video nan nodidini yeno ma...\n",
       "1                     Bro nin ello hogbutte bedu bro\n",
       "2  ‡≤™‡≥É‡≤•‡≥ç‡≤µ‡≤ø ‡≤Ö‡≤Ç‡≤¨‡≤∞‡≥ç ‡≤è‡≤®‡≥ç  ‡≤ó‡≥Å‡≤∞‡≥Ç ‡≤®‡≥Ä‡≤®‡≥Å national award win...\n",
       "3  ‡≤∏‡≤∞‡≥ç ‡≤Ö‡≤∂‡≥ç‡≤µ‡≤§‡≥ç‡≤•‡≤æ‡≤Æ ‡≤Ü ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤∞ ‡≤Æ‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤¨‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶ ‡≤Ö‡≤Ç‡≤§ ‡≤π‡≥á...\n",
       "4                                     best song ever"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\kapil\\OneDrive\\Desktop\\ML\\NLP\\Kannada_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡≤é‡≤∑‡≥ç‡≤ü‡≥Å ‡≤í‡≤ß‡≤ø‡≤¶‡≥ç‡≤Ø\n"
     ]
    }
   ],
   "source": [
    "from google.transliteration import transliterate_text\n",
    "result = transliterate_text('yesthu odhidya', lang_code='kn')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanumanthappa H S q150 \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "def preprocessing(line) :\n",
    "    # Remove words containing @\n",
    "    # line = re.sub(r'()@\\w+', r'\\1', line)\n",
    "\n",
    "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove remaining extra spaces\n",
    "    line = re.sub(\" +\", \" \", line).strip()\n",
    "\n",
    "    emoj = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U00002702-\\U000027B0\"\n",
    "    u\"\\U000024C2-\\U0001F251\"\n",
    "    u\"\\U0001f926-\\U0001f937\"\n",
    "    u\"\\U00010000-\\U0010ffff\"\n",
    "    u\"\\u2640-\\u2642\" \n",
    "    u\"\\u2600-\\u2B55\"\n",
    "    u\"\\u200d\"\n",
    "    u\"\\u23cf\"\n",
    "    u\"\\u23e9\"\n",
    "    u\"\\u231a\"\n",
    "    u\"\\ufe0f\"  # dingbats\n",
    "    u\"\\u3030\"\n",
    "                  \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', line)\n",
    "\n",
    "print(preprocessing(\"@Hanumanthappa H S q1*50 ü§ò\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H S q1*50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def remove_words(line):\n",
    "    # Remove words containing @\n",
    "    line = re.sub(r'()@\\w+', r'\\1', line)\n",
    "\n",
    "    # Remove remaining extra spaces\n",
    "    return re.sub(\" +\", \" \", line).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡≤Æ‡≤∏‡≥ç‡≤§‡≥ç ‡≤ê‡≤§‡≤ø... ‡≤Ö‡≤®‡≤æ‡≤π‡≥Å‡≤§ ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç .. ‡≤ó‡≤ø‡≤ö‡≥ç‡≤ö‡≥ç ‡≤ê‡≤§‡≤ø \n"
     ]
    }
   ],
   "source": [
    "# Remove Emojis\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "print(remove_emojis('‡≤Æ‡≤∏‡≥ç‡≤§‡≥ç ‡≤ê‡≤§‡≤ø... ‡≤Ö‡≤®‡≤æ‡≤π‡≥Å‡≤§ ‡≤∏‡≤æ‡≤Ç‡≤ó‡≥ç .. ‡≤ó‡≤ø‡≤ö‡≥ç‡≤ö‡≥ç ‡≤ê‡≤§‡≤ø ü§ò'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[en:0.999996188188539]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "detect_langs(\"['‡≤®‡≥Ü‡≤®‡≤™‡≤ø‡≤∏‡≤ø,', '‡≤á‡≤≤‡≥ç‡≤≤‡≤¶‡≤ø‡≤¶‡≥ç‡≤¶‡≤∞‡≥Ü] ['Apple', 'price', 'Banana', 'Apple', 'Boiler', 'switch', 'off', 'electric', 'bill']\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "062e9c96fbd75f066890cad56df2ea6a95362a0d7d46582632fb613cd2d20439"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
